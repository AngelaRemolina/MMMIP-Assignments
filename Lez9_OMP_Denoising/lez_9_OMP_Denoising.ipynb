{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z4OrCm2aFXhE"},"outputs":[],"source":["from skimage.io import imread\n","import numpy as np\n","from scipy.io import loadmat\n","from matplotlib import pyplot as plt\n","import time\n"]},{"cell_type":"code","source":["rootfolder = '.'"],"metadata":{"id":"VKVyjdHyIvBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Useful function for plot the 2D DCT dictionary"],"metadata":{"id":"-NB1-MvmFsot"}},{"cell_type":"code","source":["def get_dictionary_img(D):\n","    M, N = D.shape\n","    p = int(round(np.sqrt(M)))\n","    nnn = int(np.ceil(np.sqrt(N)))\n","    bound = 2\n","    img = np.ones((nnn*p+bound*(nnn-1), nnn*p+bound*(nnn-1)))\n","    for i in range(N):\n","        m = np.mod(i, nnn)\n","        n = int((i-m)/nnn)\n","        m = m * p + bound * m\n","        n = n * p + bound * n\n","        atom = D[:, i].reshape((p, p))\n","        if atom.min() < atom.max():\n","            atom = (atom - atom.min()) / (atom.max() - atom.min())\n","        img[m: m + p, n: n + p] = atom\n","\n","    return img"],"metadata":{"id":"Rey7kIlUF22r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define a function that implements the OMP"],"metadata":{"id":"elxPQr5jRssy"}},{"cell_type":"code","source":["def OMP(s, D, L, tau):\n","  M, N = D.shape\n","  x = np.zeros(N)\n","\n","  return x"],"metadata":{"id":"HEEtx02YRxui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the image and rescale it in $[0,1]$"],"metadata":{"id":"XF0xLVZyGCBc"}},{"cell_type":"code","source":["img = imread(f'{rootfolder}/data/Lena512.png') / 255\n","\n","imsz = img.shape\n","\n","# patch size\n","p = 8\n","\n","# number of elements in the patch\n","M = p ** 2\n"],"metadata":{"id":"JZXPMFW2F-W1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Corrupt the image with white gaussian noise"],"metadata":{"id":"KRBSmSG5GIPe"}},{"cell_type":"code","source":["sigma_noise = 20/255\n","# noisy_img ="],"metadata":{"id":"m1NfJRxKGKFu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the psnr of the noisy input"],"metadata":{"id":"Y4O1zq_JGPeL"}},{"cell_type":"code","source":["# psnr_noisy =\n"],"metadata":{"id":"9OtzbfA_GRIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n","ax[0].imshow(img, cmap='gray')\n","ax[0].set_title('Original image')\n","\n","ax[1].imshow(noisy_img, cmap='gray')\n","ax[1].set_title(f'Noisy image, PSNR = {psnr_noisy:.2f}')\n"],"metadata":{"id":"oMQ-c73WGT6f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load and display the dictionary learned from patches"],"metadata":{"id":"w7g7MvnnTTHT"}},{"cell_type":"code","source":["D = loadmat(f'{rootfolder}/data/dict_nat_img.mat')['D']\n","\n","# display the dct basis\n","D_img = get_dictionary_img(D)\n","plt.figure(figsize=(10,10))\n","plt.imshow(D_img, cmap='gray')"],"metadata":{"id":"BgGdWipTTXW-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Denoising\n","---------\n"],"metadata":{"id":"q6MOxJJOTuK1"}},{"cell_type":"code","source":["# initialize the estimated image\n","#img_hat =\n","\n","# initialize the weight matrix\n","#weights =\n","\n","# set the threshold\n","tau = 1.15 * p * sigma_noise\n","\n","# define the step (=p for non overlapping paches)\n","STEP = 4 # STEP = 1 might be very time consuming, start with larger STEP"],"metadata":{"id":"ue9PsXb9Txk2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Operate patchwise"],"metadata":{"id":"UhGFrleuTzyn"}},{"cell_type":"code","source":["for i in range(0, imsz[0] - p + 1, STEP):\n","    for j in range(0, imsz[1] - p + 1, STEP):\n","        # extrach the patch with the top left corner at pixel (ii, jj)\n","#        s =\n","\n","        # store and subtract the mean\n","\n","\n","        # perform the sparse coding\n","#        x =\n","\n","        # perform the reconstruction\n","#        s_hat = np.matmul(D, x)\n","\n","\n","        # add back the mean\n","#        s_hat =\n","\n","        # put the denoised patch into the estimated image using uniform weights\n","#        UPDATE img_hat\n","\n","        # store the weight of the current patch in the weight matrix\n","#        UPDATE weights"],"metadata":{"id":"iZV1qd-DT5vG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalize the estimated image with the computed weights"],"metadata":{"id":"rSc72uk8T-AS"}},{"cell_type":"code","source":["# img_hat ="],"metadata":{"id":"e9Jsy1iYT_fJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the psnr of the estimated image"],"metadata":{"id":"S7ItjKLoIy1M"}},{"cell_type":"code","source":["# psnr_hat =\n","plt.figure(figsize=(10,10))\n","plt.imshow(img_hat, cmap='gray')\n","plt.title(f'Estimated Image,\\nPSNR = {psnr_hat:.2f}')\n"],"metadata":{"id":"EuwTIEL3I1Ki"},"execution_count":null,"outputs":[]}]}