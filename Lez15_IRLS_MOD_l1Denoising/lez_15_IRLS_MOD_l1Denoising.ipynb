{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+8VAu5/aotarokHYicC7t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z4OrCm2aFXhE"},"outputs":[],"source":["from skimage.io import imread\n","import numpy as np\n","from scipy.io import loadmat\n","from matplotlib import pyplot as plt\n","import time\n"]},{"cell_type":"code","source":["rootfolder = '.'"],"metadata":{"id":"VKVyjdHyIvBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["IRLS Algorithm\n","--------------\n","Define the problem parameters\n"],"metadata":{"id":"Be43ir2EHcSE"}},{"cell_type":"code","source":["A = np.array([[1, 3], [3, 1]]) # low dimensions to plot it, you can test larger sizes\n","b = np.array([-1, 2])\n","\n","lmbda = 0.5\n"],"metadata":{"id":"8Sh4rbXeHh_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The function to be minimized is $\\frac{1}{2}\\|Ax-b\\|_2^2 + \\lambda \\|x\\|_1$"],"metadata":{"id":"qjOQIg-ZHpTc"}},{"cell_type":"code","source":["f = lambda x: 0.5 * np.sum((A @ x - b) ** 2) + lmbda * np.sum(np.abs(x))\n","\n","# derivative of f from matrix calculus\n","df = lambda x: A.T @ (A @ x) - A.T @ b\n"],"metadata":{"id":"-IZ3t2qiHoOY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot the function"],"metadata":{"id":"wjmesSGYH4YK"}},{"cell_type":"code","source":["# this function has been prepared only for the visualization sake, no need to go through this but it renders some nice\n","# graphics :)\n","F = lambda r1, r2: (r1 * A[0, 0] + r2 * A[0, 1] - b[0]) ** 2 + (r1 * A[1, 0] + r2 * A[1,1] - b[1]) ** 2 + lmbda * (np.abs(r1) + np.abs(r2))\n","xx, yy = np.meshgrid(np.arange(-10, 10, 1), np.arange(-10, 10, 1))\n","\n","fig = plt.figure()\n","ax = plt.axes(projection='3d')\n","ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])"],"metadata":{"id":"NXdKkXicH8-8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the parameters"],"metadata":{"id":"NJ8eKBxUayEV"}},{"cell_type":"code","source":["MAX_ITER = 1e3\n","TOL_DIST_X = 1e-10"],"metadata":{"id":"WcqIs0rxayEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialization: test different inizializations, the function is convex, you always converge to the same solution"],"metadata":{"id":"5J3HwecVayEX"}},{"cell_type":"code","source":["x0 = np.array([5, -10])\n","\n","# initialization\n","all_x = [x0]\n","distanceX = 1e10  # stopping criteria\n","cnt = 0\n","delta = 1e-6"],"metadata":{"id":"otG86BH8ayEX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main loop"],"metadata":{"id":"_t-ozDQvayEY"}},{"cell_type":"code","source":["while cnt < MAX_ITER and distanceX > TOL_DIST_X:\n","    x = all_x[-1]\n","\n","    # compute the weight matrix\n","    # W =\n","\n","    # solve the weighted regularized LS system\n","    # x_current =\n","\n","    # distanceX =\n","\n","    # store the estimate\n","    # update all_x\n","\n","    cnt = cnt + 1"],"metadata":{"id":"5a49h-zsayEY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot all the estimates"],"metadata":{"id":"BNNKjaJmayEY"}},{"cell_type":"code","source":["# plot the new estimate\n","xxplot = [x[0] for x in all_x]\n","yyplot = [x[1] for x in all_x]\n","zzplot = F(np.array(xxplot), np.array(yyplot))\n","\n","fig = plt.figure(figsize=(10,10))\n","ax = plt.axes(projection='3d')\n","ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])\n","ax.plot3D(xxplot, yyplot, zzplot, 'r-o')"],"metadata":{"id":"s3NrMKd3ayEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'nr of iteration of IRLS (before stopping criteria met): {cnt}\\n')\n","print(f'Solution of IRLS: [{x_current[0]:.4f}, {x_current[1]:.4f}]\\n')\n","print(f'Value of the functional: {f(x_current):.4f}\\n')\n"],"metadata":{"id":"yNFvIs7uayEa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MOD dictionary learning\n","-----------------------\n","Useful function for plot the 2D DCT dictionary"],"metadata":{"id":"P1g68tnc6uoK"}},{"cell_type":"code","source":["def get_dictionary_img(D):\n","    M, N = D.shape\n","    p = int(round(np.sqrt(M)))\n","    nnn = int(np.ceil(np.sqrt(N)))\n","    bound = 2\n","    img = np.ones((nnn*p+bound*(nnn-1), nnn*p+bound*(nnn-1)))\n","    for i in range(N):\n","        m = np.mod(i, nnn)\n","        n = int((i-m)/nnn)\n","        m = m * p + bound * m\n","        n = n * p + bound * n\n","        atom = D[:, i].reshape((p, p))\n","        if atom.min() < atom.max():\n","            atom = (atom - atom.min()) / (atom.max() - atom.min())\n","        img[m: m + p, n: n + p] = atom\n","\n","    return img"],"metadata":{"id":"Rey7kIlUF22r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define a function to perform the sparse coding using your favorite algorithm (IRLS, FISTA or ISTA)"],"metadata":{"id":"BptBSuNQ64ak"}},{"cell_type":"code","source":["def IRLS(s, D, lmbda, x0=None):\n","    if x0 is None:\n","        x0 = np.zeros(D.shape[1])\n","    delta = 1e-6\n","    max_iter = 20\n","    distanceX = 1e10\n","    toll_x = 1e-3\n","\n","    x = x0\n","\n","    cnt = 0\n","    while cnt < max_iter or distanceX > toll_x:\n","        W = np.diag(1 / (np.abs(x) + delta))\n","        # solve the weighted regularized LS system\n","        x_new = np.linalg.solve((2 * lmbda * W + D.T @ D), D.T @ s)\n","        distanceX = np.linalg.norm(x - x_new, ord=2)\n","        x = x_new\n","        cnt = cnt + 1\n","    return x_new"],"metadata":{"id":"1MDlsdgp68Ci"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the image and rescale it in [0,1]"],"metadata":{"id":"EVoq64RP6-kk"}},{"cell_type":"code","source":["img = imread('BM3D_images/barbara.png') / 255\n","imsz = img.shape\n"],"metadata":{"id":"fRItOr027BVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the parameters"],"metadata":{"id":"eS9awY-77EeL"}},{"cell_type":"code","source":["# patch size\n","p = 8\n","\n","# number of elements in the patchfrom skimage.io import imread\n","M = p ** 2\n","\n","# number of columns in the dictionary\n","N = 96\n","\n","# extract the random patches from the noisy image\n","npatch = 1000\n","\n","# only few MOD iterations are needed for a good dictionary\n","max_iter = 10\n","\n","lmbda = 0.1"],"metadata":{"id":"oii0m41f7F26"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extract $npatch$ random patches from the image\n"],"metadata":{"id":"iwKu4JL87Je2"}},{"cell_type":"code","source":["S = np.zeros((M, npatch))\n","#S ="],"metadata":{"id":"OgXVqGNl7Ttq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize the dictionary randomly and the normalize the columns"],"metadata":{"id":"ynOk7uYr7cvU"}},{"cell_type":"code","source":["# D =\n"],"metadata":{"id":"rrkaVUCO7fgt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialize a matrix for the coefficients of all the patches"],"metadata":{"id":"NZltkicV7iht"}},{"cell_type":"code","source":["# X ="],"metadata":{"id":"kzj2vAn77nwc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main loop"],"metadata":{"id":"pJx4qIsh7oSj"}},{"cell_type":"code","source":["for iter in range(max_iter):\n","\n","    # perform the sparse coding for all the patches in S\n","    for n in range(npatch):\n","        s = S[:, n]\n","        # x =\n","        X[:, n] = x\n","\n","    # MOD update\n","    # D =\n","\n","    # normalize the column\n","    # D =\n"],"metadata":{"id":"1Z8XQNrG7qLQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Show the dictionary"],"metadata":{"id":"MZGaziVS7rdn"}},{"cell_type":"code","source":["img_dict = get_dictionary_img(D)\n","plt.figure()\n","plt.imshow(img_dict, cmap='gray')\n"],"metadata":{"id":"FqHV9pHR7saw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Denoising via $\\ell^1$ sparse coding\n","------------------------------------\n","Set the noise level and add the noise to the original image"],"metadata":{"id":"luYMvFoa7wOp"}},{"cell_type":"code","source":["sigma_noise = 20/255\n","noisy_img = img + np.random.normal(size=imsz) * sigma_noise\n"],"metadata":{"id":"6JBB5ylJ71HE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compue the psnr of the noisy input"],"metadata":{"id":"Y7HK4Qlr8Hqa"}},{"cell_type":"code","source":["# psnr_noisy =\n"],"metadata":{"id":"iTO-fkTj8FwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n","ax[0].imshow(img, cmap='gray')\n","ax[0].set_title('Original image')\n","\n","ax[1].imshow(noisy_img, cmap='gray')\n","ax[1].set_title(f'Noisy image, PSNR = {psnr_noisy:.2f}')"],"metadata":{"id":"Y4k9TAEv8OqK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use the dictionary computed with the MOD or load a pretrained dictionary $D$"],"metadata":{"id":"9gEUzAQJ8Qv0"}},{"cell_type":"code","source":["D = loadmat(f'{rootfolder}/data/dict_nat_img.mat')['D']\n","\n","# show the dictionary\n","D_img = get_dictionary_img(D)\n","plt.figure(figsize=(10,10))\n","plt.imshow(D_img, cmap='gray')\n"],"metadata":{"id":"Q1rO7pMs8ZHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the estimated image\n","img_hat = np.zeros_like(img)\n","\n","# initialize the weight matrix\n","weights = np.zeros_like(img)\n","\n","# set the threshold\n","tau = 2.2\n","lmbda = tau * sigma_noise\n","\n","# define the step (=p for non overlapping paches)\n","STEP = 4 # STEP = 1 might be very time consuming, start with larger STEP"],"metadata":{"id":"ue9PsXb9Txk2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Operate patchwise"],"metadata":{"id":"UhGFrleuTzyn"}},{"cell_type":"code","source":["for i in range(0, imsz[0] - p + 1, STEP):\n","    for j in range(0, imsz[1] - p + 1, STEP):\n","        # extrach the patch with the top left corner at pixel (ii, jj)\n","        # s =\n","\n","        # store and subtract the mean\n","\n","        # perform the sparse coding of the patch s to compute the coefficients vector x\n","        # x =\n","\n","        # perform the reconstruction\n","        # s_hat =\n","\n","        w = 1\n","\n","        # add back the mean\n","        # s_hat =\n","\n","        # put the denoised patch into the estimated image using uniform weights\n","        # update img_hat\n","\n","        # store the weight of the current patch in the weight matrix\n","        # update weights"],"metadata":{"id":"iZV1qd-DT5vG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalize the estimated image with the computed weights"],"metadata":{"id":"rSc72uk8T-AS"}},{"cell_type":"code","source":["# img_hat ="],"metadata":{"id":"e9Jsy1iYT_fJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compute the psnr of the estimated image"],"metadata":{"id":"S7ItjKLoIy1M"}},{"cell_type":"code","source":["psnr_hat = 10*np.log10(1 / np.mean((img - img_hat) ** 2))\n","plt.figure(figsize=(10,10))\n","plt.imshow(img_hat, cmap='gray')\n","plt.title(f'Estimated Image,\\nPSNR = {psnr_hat:.2f}')\n"],"metadata":{"id":"EuwTIEL3I1Ki"},"execution_count":null,"outputs":[]}]}