{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QP0WXBPEfQ5"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky9Bat90FNla"
   },
   "outputs": [],
   "source": [
    "rootfolder = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NB1-MvmFsot"
   },
   "source": [
    "Useful function for plot the 2D DCT dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M = D.shape[0]\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    bound = 2\n",
    "    img = np.ones((p*p+bound*(p-1), p*p+bound*(p-1)))\n",
    "    for i in range(M):\n",
    "        m = np.mod(i, p)\n",
    "        n = int((i-m)/p)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m: m + p, n: n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq78PWSDFw7G"
   },
   "source": [
    "Load the image and rescale it in $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHuWhKkwFdIR"
   },
   "outputs": [],
   "source": [
    "# img = imread(f'{rootfolder}/data/cameraman.png') / 255\n",
    "img = imread(f'{rootfolder}/data/barbara.png') / 255\n",
    "# img = imread(f'{rootfolder}/data/Lena512.png') / 255\n",
    "\n",
    "imsz = img.shape\n",
    "\n",
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patch\n",
    "M = p ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBSmSG5GIPe"
   },
   "source": [
    "Corrupt the image with white gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1NfJRxKGKFu"
   },
   "outputs": [],
   "source": [
    "sigma_noise = 20/255\n",
    "noisy_img = img + np.random.normal(size=imsz) * sigma_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1zq_JGPeL"
   },
   "source": [
    "Compute the psnr of the noisy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OtzbfA_GRIA"
   },
   "outputs": [],
   "source": [
    "mse = np.mean((img-noisy_img)**2)\n",
    "psnr_noisy = 10*np.log10(1/mse)\n",
    "psnr_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMQ-c73WGT6f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap='gray')\n",
    "ax[1].set_title(f'Noisy image, PSNR = {psnr_noisy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpWVlOfFGDL3"
   },
   "source": [
    "Generate the Global PCA basis for this image\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngJAhBG8Fr1p"
   },
   "source": [
    "Set the parameters for denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTiCU7aMFvIs"
   },
   "outputs": [],
   "source": [
    "# set the threshold for the Hard Thresholding\n",
    "tau = 3 * sigma_noise # Donoho says: sigma * sqrt(2*log(p^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn_xtpoQLSgH"
   },
   "source": [
    "Stack all the image patches in a large matrix $S$. Each patch goes in a column of $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7EXaqMdGJn_"
   },
   "outputs": [],
   "source": [
    "n = 64\n",
    "m = (imsz[0]+1 - p)*(imsz[1]+1 - p)\n",
    "S = np.zeros((n,m))\n",
    "cont = 0\n",
    "for i in range(0, imsz[0] - p + 1):\n",
    "    for j in range(0, imsz[1] - p + 1):\n",
    "        x_patch = noisy_img[i:i+p, j:j+p].reshape(-1)\n",
    "        S[:,cont] = x_patch\n",
    "        cont += 1\n",
    "\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9uzewMlGeYZ"
   },
   "source": [
    "Compute $\\tilde S$ by zero centering $S$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQkZT90BGhCc"
   },
   "outputs": [],
   "source": [
    "avg_patch = np.mean(S, axis=0)\n",
    "print(avg_patch)\n",
    "Stilde = S - avg_patch\n",
    "Stilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuySyJuKGj3v"
   },
   "source": [
    "Compute the PCA transformation via SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqQnUMPIGn-v"
   },
   "outputs": [],
   "source": [
    "optimized_S = np.dot(Stilde,Stilde.T)\n",
    "U, Sigma, V = np.linalg.svd(optimized_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoPCw655Gp8p"
   },
   "source": [
    "Show the learned PCA basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_fyAAGSGsTT"
   },
   "outputs": [],
   "source": [
    "U_img = get_dictionary_img(U)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(U_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM-GG-pGHwI7"
   },
   "source": [
    "Patch-based denoising\n",
    "---------------------\n",
    "Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMKEOosIG8qG"
   },
   "outputs": [],
   "source": [
    "STEP = 1\n",
    "\n",
    "# initialize the estimated image\n",
    "img_hat = np.zeros_like(img)\n",
    "\n",
    "# initialize the weight matrix\n",
    "weights = np.zeros_like(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xs9zBzMpIBn0"
   },
   "outputs": [],
   "source": [
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        # extrach the patch with the top left corner at pixel (ii, jj)\n",
    "        s = noisy_img[i:i+p, j:j+p]\n",
    "\n",
    "        # Preprocessing: remember to subtract the avg_patch (preprocessing used for PCA)\n",
    "        # avg_patch = np.mean(s)\n",
    "        # print(avg_patch)\n",
    "        # print(s)      \n",
    "        s = s - avg_patch[i * (imsz[1] - p + 1) + j]#avg_patch\n",
    "        # print(s)\n",
    "        \n",
    "        # compute the representation w.r.t. the PCA basis\n",
    "        x = np.dot(U.T,s.reshape(-1))\n",
    "        # perform the hard thresholding\n",
    "        x_hat = np.where(np.abs(x) > tau, x, 0)\n",
    "        # x_hat[0,0] = x[0,0] # to ask: leave original value of DC\n",
    "        \n",
    "        # synthesis: perform the reconstruction\n",
    "        y_hat = np.dot(U,x_hat)\n",
    "\n",
    "        # add the avg patch back\n",
    "        y_hat += avg_patch\n",
    "\n",
    "        # compute the weight for the reconstructed patch\n",
    "        w = 1\n",
    "\n",
    "        # put the compressed patch into the compressed image using the computed weight\n",
    "        # UPDATE img_hat\n",
    "        img_hat[i:i+p, j:j+p] = (y_hat*w).reshape((p,p))\n",
    "\n",
    "        # store the weight of the current patch in the weight matrix\n",
    "        # UPDATE weights\n",
    "        weights[i:i+p, j:j+p] += w\n",
    "        \n",
    "\n",
    "# normalize the estimated image with the computed weights\n",
    "img_hat = img_hat / weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ItjKLoIy1M"
   },
   "source": [
    "Compute the psnr of the estimated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuwTIEL3I1Ki"
   },
   "outputs": [],
   "source": [
    "mse = np.mean((img-img_hat)**2)\n",
    "psnr_hat = 10*np.log10(1/mse)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_hat, cmap='gray')\n",
    "plt.title(f'Estimated Image,\\nPSNR = {psnr_hat:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZxmRR05VnbpUbEZZN76xR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
